{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Day39_yolov3_keras_HW.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CG77DrrB2CrU"},"source":["## 作業\n","該版本的 yolov3 實現邏輯主要寫在 `yolo.py` 中 `YOLO` 這個 class 的 `detect_image` ，其回傳已畫上檢測到的 bboxes 和物件類別的圖片。\n","\n","1. 請嘗試閱讀及盡量理解 `detect_image` 的程式碼片段\n","2. 請修改/模仿 `detect_image` 的寫法，使其回傳 bboxes 的信息、信心度及 bboxes 對應的類別\n"]},{"cell_type":"code","metadata":{"id":"t8PrRe1al54v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":658},"outputId":"3a72966a-92a4-4da3-c3e9-303437c23ecd","executionInfo":{"status":"ok","timestamp":1586262289536,"user_tz":-480,"elapsed":48165,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["!pip install tensorflow==1.14.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n","\u001b[K     |████████████████████████████████| 109.2MB 49kB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 39.0MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 47.1MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.2.0\n","    Uninstalling tensorboard-2.2.0:\n","      Successfully uninstalled tensorboard-2.2.0\n","  Found existing installation: tensorflow-estimator 2.2.0rc0\n","    Uninstalling tensorflow-estimator-2.2.0rc0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n","  Found existing installation: tensorflow 2.2.0rc2\n","    Uninstalling tensorflow-2.2.0rc2:\n","      Successfully uninstalled tensorflow-2.2.0rc2\n","Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586262318202,"user_tz":-480,"elapsed":23653,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"id":"NCEP-DG0VxlV","outputId":"46abb84f-5459-4ab5-8ec7-e39c7e231819","colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m_Xqvv86nqtt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"f23394c7-c4ae-4358-f506-24852ba0e08c","executionInfo":{"status":"ok","timestamp":1586262638837,"user_tz":-480,"elapsed":4198,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["!git clone https://github.com/qqwweee/keras-yolo3\n","%cd keras-yolo3\n","!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Cloning into 'keras-yolo3'...\n","remote: Enumerating objects: 144, done.\u001b[K\n","remote: Total 144 (delta 0), reused 0 (delta 0), pack-reused 144\u001b[K\n","Receiving objects: 100% (144/144), 151.08 KiB | 2.48 MiB/s, done.\n","Resolving deltas: 100% (65/65), done.\n","/content/keras-yolo3\n","coco_annotation.py  kmeans.py\ttrain_bottleneck.py  yolo.py\n","convert.py\t    LICENSE\ttrain.py\t     yolov3.cfg\n","darknet53.cfg\t    model_data\tvoc_annotation.py    yolov3-tiny.cfg\n","font\t\t    README.md\tyolo3\t\t     yolo_video.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586264107135,"user_tz":-480,"elapsed":1436948,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"id":"Avxgh7T7yp2g","outputId":"2116c1b2-bfb2-4972-91a9-b6f113030300","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import os\n","import subprocess\n","\n","if not os.path.exists(\"model_data/yolo.h5\"):\n","  # 下載 yolov3 的網路權重，並且把權重轉換為 keras 能夠讀取的格式\n","  print(\"Model doesn't exist, downloading...\")\n","  os.system(\"wget https://pjreddie.com/media/files/yolov3.weights\")\n","  print(\"Converting yolov3.weights to yolo.h5...\")\n","  os.system(\"python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\")\n","else:\n","  print(\"Model exist\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model doesn't exist, downloading...\n","Converting yolov3.weights to yolo.h5...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MWPFl6dU1rjr","colab":{"base_uri":"https://localhost:8080/","height":689},"outputId":"b926c401-f5b9-4a3e-cae2-4f80bbed0569","executionInfo":{"status":"ok","timestamp":1586264111423,"user_tz":-480,"elapsed":4271,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["# 下載圖片範例，如果已經下載過就可以註解掉\n","!wget https://github.com/pjreddie/darknet/blob/master/data/dog.jpg?raw=true -O dog.jpg\n","!wget https://github.com/pjreddie/darknet/blob/master/data/horses.jpg?raw=true -O horses.jpg"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-04-07 12:55:08--  https://github.com/pjreddie/darknet/blob/master/data/dog.jpg?raw=true\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github.com/pjreddie/darknet/raw/master/data/dog.jpg [following]\n","--2020-04-07 12:55:08--  https://github.com/pjreddie/darknet/raw/master/data/dog.jpg\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/pjreddie/darknet/master/data/dog.jpg [following]\n","--2020-04-07 12:55:08--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/dog.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 163759 (160K) [image/jpeg]\n","Saving to: ‘dog.jpg’\n","\n","dog.jpg             100%[===================>] 159.92K  --.-KB/s    in 0.03s   \n","\n","2020-04-07 12:55:08 (4.64 MB/s) - ‘dog.jpg’ saved [163759/163759]\n","\n","--2020-04-07 12:55:09--  https://github.com/pjreddie/darknet/blob/master/data/horses.jpg?raw=true\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github.com/pjreddie/darknet/raw/master/data/horses.jpg [following]\n","--2020-04-07 12:55:10--  https://github.com/pjreddie/darknet/raw/master/data/horses.jpg\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/pjreddie/darknet/master/data/horses.jpg [following]\n","--2020-04-07 12:55:10--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/horses.jpg\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 133495 (130K) [image/jpeg]\n","Saving to: ‘horses.jpg’\n","\n","horses.jpg          100%[===================>] 130.37K  --.-KB/s    in 0.03s   \n","\n","2020-04-07 12:55:10 (4.17 MB/s) - ‘horses.jpg’ saved [133495/133495]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586264112233,"user_tz":-480,"elapsed":797,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"id":"-vhfpWt92WZS","outputId":"16d23fe3-1f1c-4c8e-c23f-9f04328ce716","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 將 yolo.py 所需要的套件載入\n","import colorsys\n","import os\n","from timeit import default_timer as timer\n","\n","import numpy as np\n","from keras import backend as K\n","from keras.models import load_model\n","from keras.layers import Input\n","from PIL import Image, ImageFont, ImageDraw\n","\n","from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n","from yolo3.utils import letterbox_image\n","import os\n","from keras.utils import multi_gpu_model"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i-AMDH1d4ESV","colab":{}},"source":["# 定義 YOLO class\n","class YOLO(object):\n","    _defaults = {\n","        \"model_path\": 'model_data/yolo.h5',\n","        \"anchors_path\": 'model_data/yolo_anchors.txt',\n","        \"classes_path\": 'model_data/coco_classes.txt',\n","        \"score\" : 0.3,\n","        \"iou\" : 0.45,\n","        \"model_image_size\" : (416, 416),\n","        \"gpu_num\" : 1,\n","    }\n","\n","    @classmethod\n","    def get_defaults(cls, n):\n","        if n in cls._defaults:\n","            return cls._defaults[n]\n","        else:\n","            return \"Unrecognized attribute name '\" + n + \"'\"\n","\n","    def __init__(self, **kwargs):\n","        self.__dict__.update(self._defaults) # set up default values\n","        self.__dict__.update(kwargs) # and update with user overrides\n","        self.class_names = self._get_class()\n","        self.anchors = self._get_anchors()\n","        self.sess = K.get_session()\n","        self.boxes, self.scores, self.classes = self.generate()\n","\n","    def _get_class(self):\n","        classes_path = os.path.expanduser(self.classes_path)\n","        with open(classes_path) as f:\n","            class_names = f.readlines()\n","        class_names = [c.strip() for c in class_names]\n","        return class_names\n","\n","    def _get_anchors(self):\n","        anchors_path = os.path.expanduser(self.anchors_path)\n","        with open(anchors_path) as f:\n","            anchors = f.readline()\n","        anchors = [float(x) for x in anchors.split(',')]\n","        return np.array(anchors).reshape(-1, 2)\n","\n","    def generate(self):\n","        model_path = os.path.expanduser(self.model_path)\n","        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n","\n","        # Load model, or construct model and load weights.\n","        num_anchors = len(self.anchors)\n","        num_classes = len(self.class_names)\n","        is_tiny_version = num_anchors==6 # default setting\n","        try:\n","            self.yolo_model = load_model(model_path, compile=False)\n","        except:\n","            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n","                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n","            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n","        else:\n","            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n","                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n","                'Mismatch between model and given anchor and class sizes'\n","\n","        print('{} model, anchors, and classes loaded.'.format(model_path))\n","\n","        # Generate colors for drawing bounding boxes.\n","        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n","                      for x in range(len(self.class_names))]\n","        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n","        self.colors = list(\n","            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n","                self.colors))\n","        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n","        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n","        np.random.seed(None)  # Reset seed to default.\n","\n","        # Generate output tensor targets for filtered bounding boxes.\n","        self.input_image_shape = K.placeholder(shape=(2, ))\n","        if self.gpu_num>=2:\n","            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n","        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n","                len(self.class_names), self.input_image_shape,\n","                score_threshold=self.score, iou_threshold=self.iou)\n","        return boxes, scores, classes\n","\n","    # 更改 detect_image 使得其回傳需要的信息\n","    def detect_image(self, image):\n","        start = timer()\n","\n","        if self.model_image_size != (None, None):\n","            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n","            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n","            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n","        else:\n","            new_image_size = (image.width - (image.width % 32),\n","                              image.height - (image.height % 32))\n","            boxed_image = letterbox_image(image, new_image_size)\n","        image_data = np.array(boxed_image, dtype='float32')\n","\n","        print(image_data.shape)\n","        image_data /= 255.\n","        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n","\n","        out_boxes, out_scores, out_classes = self.sess.run(\n","            [self.boxes, self.scores, self.classes],\n","            feed_dict={\n","                self.yolo_model.input: image_data,\n","                self.input_image_shape: [image.size[1], image.size[0]],\n","                K.learning_phase(): 0\n","            })\n","\n","        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n","\n","        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n","                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n","        thickness = (image.size[0] + image.size[1]) // 300\n","\n","        for i, c in reversed(list(enumerate(out_classes))):\n","            predicted_class = self.class_names[c]\n","            box = out_boxes[i]\n","            score = out_scores[i]\n","\n","            label = '{} {:.2f}'.format(predicted_class, score)\n","            draw = ImageDraw.Draw(image)\n","            label_size = draw.textsize(label, font)\n","\n","            top, left, bottom, right = box\n","            top = max(0, np.floor(top + 0.5).astype('int32'))\n","            left = max(0, np.floor(left + 0.5).astype('int32'))\n","            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n","            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n","            print(label, (left, top), (right, bottom))\n","\n","            if top - label_size[1] >= 0:\n","                text_origin = np.array([left, top - label_size[1]])\n","            else:\n","                text_origin = np.array([left, top + 1])\n","\n","            # My kingdom for a good redistributable image drawing library.\n","            for i in range(thickness):\n","                draw.rectangle(\n","                    [left + i, top + i, right - i, bottom - i],\n","                    outline=self.colors[c])\n","            draw.rectangle(\n","                [tuple(text_origin), tuple(text_origin + label_size)],\n","                fill=self.colors[c])\n","            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n","            del draw\n","\n","        end = timer()\n","        print(end - start)\n","        return out_boxes, out_scores, out_classes # Hint: 在這裡更改程式碼即可\n","\n","    def close_session(self):\n","        self.sess.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586265155602,"user_tz":-480,"elapsed":16955,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"id":"sncElkSw4l7c","outputId":"40f1b168-018c-4134-a511-24bf003a94f5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["yolo = YOLO() # 初始化 YOLO class"],"execution_count":19,"outputs":[{"output_type":"stream","text":["model_data/yolo.h5 model, anchors, and classes loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Swa6_91Dvwl8","colab_type":"code","colab":{}},"source":["image = Image.open('./dog.jpg')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rl6Xi6-7wjN-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"outputId":"ec5d6fae-36ce-4df4-a0c9-1034878c1202","executionInfo":{"status":"ok","timestamp":1586265160547,"user_tz":-480,"elapsed":17029,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["results = yolo.detect_image(image)\n","out_boxes, out_scores, out_classes = results"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(416, 416, 3)\n","Found 5 boxes for img\n","dog 0.51 (186, 243) (299, 442)\n","cat 0.77 (183, 246) (299, 461)\n","truck 0.97 (444, 76) (695, 162)\n","car 0.48 (437, 88) (700, 155)\n","bicycle 0.93 (188, 118) (560, 446)\n","4.74743149599999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1jLImK8QxUgA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":151},"outputId":"fca43d71-07b9-48e7-f6c3-128520be307b","executionInfo":{"status":"ok","timestamp":1586265161357,"user_tz":-480,"elapsed":808,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["print(out_boxes)\n","print(out_scores)\n","print(out_classes) \n","print([yolo.class_names[c] for c in out_classes])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[[117.99512  187.6085   445.95865  559.58856 ]\n"," [ 87.84123  437.3248   154.77585  699.8518  ]\n"," [ 75.659424 443.7811   161.55267  695.02344 ]\n"," [246.08243  183.28366  461.15958  298.79666 ]\n"," [243.09843  186.0644   442.27176  298.53345 ]]\n","[0.92651933 0.4755951  0.9671805  0.77450716 0.5149189 ]\n","[ 1  2  7 15 16]\n","['bicycle', 'car', 'truck', 'cat', 'dog']\n"],"name":"stdout"}]}]}